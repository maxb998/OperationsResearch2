#include "Tsp.h"

#include <pthread.h>
#include <time.h>
#include <unistd.h> // needed to get the _POSIX_MONOTONIC_CLOCK and measure time
#include <stdio.h>

// multiplier to decrease temperature at each iteration. MUST be between 0 and 1, and should be very close to one
#define TEMPERATURE_MULTIPLIER 0.99
// temperature at which annealing stops and runs 2opt since we can basically expect mostly improving moves from that point on
#define STOP_TEMP 0.1 
// number of simulations of a random move before giving up for this iteration(avoids endless loops)
#define TRIES_BEFORE_TEMP_REDUCTION 500

// #define USE_RATIO_ACCEPTANCE // it does not seem to work well

typedef struct
{
    float offset;
    int index1;
    int index2;
    float newEdge1Cost;
    float newEdge2Cost;
} MoveData;

typedef struct
{
    Solution *bestSol;
    pthread_mutex_t mutex;
    double timeLimit;
    double startTemperature;
} ThreadSharedData;

typedef struct
{
    ThreadSharedData *thShared;
    Solution sol;
    unsigned int rndState;
    int iters;
    int nonImprovingIters;
    double temperature;
    double nNodesSqrt;

    float *costCache;
    #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE)) // useful for 2opt
        float *X;
        float *Y;
    #endif

} __attribute__((aligned(64))) ThreadSpecificData;

static inline ThreadSharedData initThreadSharedData(Solution *sol, double timeLimit);
static inline void destroyThreadSharedData(ThreadSharedData *thShared);
static inline ThreadSpecificData initThreadSpecificData(Solution *sol, ThreadSharedData *thShared, unsigned int rndState);
static inline void destroyThreadSpecificData(ThreadSpecificData *thSpecific);

// Function to run Simulated Annealing on every thread
static void * runSimulatedAnnealing(void * arg);

// Compute random move saving new edges cost, locations and offset
static inline MoveData randomMoveOffsetEstimation(ThreadSpecificData *thSpecific);

// Decide wheter to accept a move generated by randomMoveOffsetEstimation or to reject it based on temperature and move offset
static inline bool acceptMove(ThreadSpecificData *thSpecific, MoveData s);

// If move has been accepted just perform it. Basically the same code as in 2opt
static inline void performMove(ThreadSpecificData *thSpecific, MoveData MoveData);

// Update solution by cloning current solution into bestSolution. Returns true if solution is updated, false otherwise
static inline bool updateBestSolution(ThreadSpecificData *thSpecific);

// Set thSpecific internal data to match the best solution
static inline void restartOnBestSol(ThreadSpecificData *thSpecific);

void SimulatedAnnealing(Solution *sol, double timeLimit)
{
    struct timespec timeStruct;
    clock_gettime(_POSIX_MONOTONIC_CLOCK, &timeStruct);
    double startTime = cvtTimespec2Double(timeStruct);

    // need to save this since at some point this algorithms runs 2opt which changes this value resulting in inconsitencies
    double solutionArrivalTime = sol->execTime;

    if (!checkSolution(sol))
        throwError("SimulatedAnnealing: Input solution is not valid");

    if (sol->instance->params.annealingTemperature == -1)
        sol->instance->params.annealingTemperature = pow(sol->instance->nNodes, 1.4); // kind of random for now
    
    LOG(LOG_LVL_NOTICE, "Starting temperature = %lf", sol->instance->params.annealingTemperature);

    // initialization of threads data
    ThreadSharedData thShared = initThreadSharedData(sol, startTime + timeLimit);

    ThreadSpecificData thSpecific[MAX_THREADS];
    pthread_t threads[MAX_THREADS];
    for (int i = 0; i < sol->instance->params.nThreads; i++)
    {
        thSpecific[i] = initThreadSpecificData(sol, &thShared, (unsigned int)rand());
        pthread_create(&threads[i], NULL, runSimulatedAnnealing, &thSpecific[i]);
    }

    int iters = 0;
    for (int i = 0; i < sol->instance->params.nThreads; i++)
    {
        pthread_join(threads[i], NULL);
        iters += thSpecific[i].iters;
        destroyThreadSpecificData(&thSpecific[i]);
    }

    destroyThreadSharedData(&thShared);

    clock_gettime(_POSIX_MONOTONIC_CLOCK, &timeStruct);
    double currentTime = cvtTimespec2Double(timeStruct);

    sol->execTime = solutionArrivalTime + currentTime - startTime;

    LOG(LOG_LVL_NOTICE, "Total number of iterations: %d", iters);
    LOG(LOG_LVL_NOTICE, "Iterations-per-second: %lf", (double)iters/(currentTime-startTime));
}

static inline ThreadSharedData initThreadSharedData(Solution *sol, double timeLimit)
{
    ThreadSharedData thShared = { 
        .bestSol = sol,
        .timeLimit = timeLimit,
        .startTemperature = sol->instance->params.annealingTemperature
    };

    pthread_mutex_init(&thShared.mutex, NULL);
    return thShared;
}

static inline void destroyThreadSharedData(ThreadSharedData *thShared)
{
    pthread_mutex_destroy(&thShared->mutex);
}

static inline ThreadSpecificData initThreadSpecificData(Solution *sol, ThreadSharedData *thShared, unsigned int rndState)
{
    Instance *inst = sol->instance;
    int n = inst->nNodes;

    ThreadSpecificData thSpecific = {
        .iters = 0,
        .nonImprovingIters = 0,
        .nNodesSqrt = sqrt(n),
        .rndState = rndState,
        .thShared = thShared
    };

    size_t memToAlloc = (n + AVX_VEC_SIZE) * (sizeof(float) + sizeof(int));
    #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
        memToAlloc += (n + AVX_VEC_SIZE) * sizeof(float) * 2;
    #endif
    thSpecific.sol.indexPath = malloc(memToAlloc);
    if (!thSpecific.sol.indexPath)
        throwError("SimulatedAnnealing -> initThreadSpecificData: failed to allocate memory");

    thSpecific.costCache = (float*)&thSpecific.sol.indexPath[n+AVX_VEC_SIZE];
    
    #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
        thSpecific.X = &thSpecific.costCache[n + AVX_VEC_SIZE];
        thSpecific.Y = &thSpecific.X[n + AVX_VEC_SIZE];
    #endif

    // cloning of solution and setup of remaining data
    pthread_mutex_lock(&thShared->mutex);
    cloneSolution(sol, &thSpecific.sol);
    pthread_mutex_unlock(&thShared->mutex);

    thSpecific.sol.indexPath[n] = thSpecific.sol.indexPath[0];
    
    #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
        for (int i = 0; i < n+1; i++)
        {
            thSpecific.X[i] = inst->X[sol->indexPath[i]];
            thSpecific.Y[i] = inst->Y[sol->indexPath[i]];
        }
        for (int i = n + 1; i < n + AVX_VEC_SIZE; i++)
        {
            thSpecific.X[i] = INFINITY;
            thSpecific.Y[i] = INFINITY;
        }
    #endif

    for (int i = 0; i < n; i++)
        #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
            thSpecific.costCache[i] = computeEdgeCost(thSpecific.X[i], thSpecific.Y[i], thSpecific.X[i+1], thSpecific.Y[i+1], inst);
        #elif (COMPUTATION_TYPE == COMPUTE_OPTION_USE_COST_MATRIX)
            thSpecific.costCache[i] = inst->edgeCostMat[thSpecific.sol.indexPath[i] * (size_t)n + thSpecific.sol.indexPath[i+1]];
        #endif

    for (int i = n; i < n + AVX_VEC_SIZE; i++) // according to 2opt notation
        thSpecific.costCache[i] = INFINITY;

    return thSpecific;
}

static inline void destroyThreadSpecificData(ThreadSpecificData *thSpecific)
{
    free(thSpecific->sol.indexPath);
    thSpecific->sol.indexPath = NULL;
    thSpecific->costCache = NULL;
    #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
        thSpecific->X = NULL;
        thSpecific->Y = NULL;
    #endif
}

static void * runSimulatedAnnealing(void * arg)
{
    ThreadSpecificData *thSpecific = (ThreadSpecificData*)arg;
    ThreadSharedData *thShared = thSpecific->thShared;
    Solution *sol = &thSpecific->sol;
    Instance *inst = sol->instance;

    struct timespec timeStruct;
    clock_gettime(_POSIX_MONOTONIC_CLOCK, &timeStruct);
    double currentTime = cvtTimespec2Double(timeStruct);

    while (currentTime < thShared->timeLimit)
    {

        if (thSpecific->nonImprovingIters > inst->params.metaRestartThreshold)
        {
            restartOnBestSol(thSpecific);
            thSpecific->nonImprovingIters = 0;
        }

        while ((currentTime < thShared->timeLimit) && (thSpecific->temperature > STOP_TEMP))
        {
            MoveData move;
            bool accepted = false;
            for (int i = 0; (i < TRIES_BEFORE_TEMP_REDUCTION) && !accepted; i++)
            {
                move = randomMoveOffsetEstimation(thSpecific);
                accepted = acceptMove(thSpecific, move);
            }
            
            if (accepted)
            {
                performMove(thSpecific, move);
                LOG(LOG_LVL_TRACE, "Temp[%lf]: Performed new move using indices (%5d,%5d) with offset %f. New solution cost = %lf", thSpecific->temperature, move.index1, move.index2, move.offset, cvtCost2Double(thSpecific->sol.cost));
            }

            if (updateBestSolution(thSpecific))
                thSpecific->nonImprovingIters = 0;

            thSpecific->temperature *= TEMPERATURE_MULTIPLIER;

            clock_gettime(_POSIX_MONOTONIC_CLOCK, &timeStruct);
            currentTime = cvtTimespec2Double(timeStruct);
        }
        
        // "fake" remaining annealing move with very low temperature (only improving moves) using 2opt, way less time than just waiting for improving moves to come up at random
        #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
            apply2OptBestFix_fastIteratively(sol, thSpecific->X, thSpecific->Y, thSpecific->costCache);
        #elif (COMPUTATION_TYPE == COMPUTE_OPTION_USE_COST_MATRIX)
            apply2OptBestFix_fastIteratively(sol, thSpecific->costCache);
        #endif

        if (updateBestSolution(thSpecific))
            thSpecific->nonImprovingIters = 0;
        else
            thSpecific->nonImprovingIters++;

        thSpecific->temperature = thShared->startTemperature;
        thSpecific->iters++;
        thSpecific->nonImprovingIters++;

        // 2opt might take some time optimizing so get time again
        clock_gettime(_POSIX_MONOTONIC_CLOCK, &timeStruct);
        currentTime = cvtTimespec2Double(timeStruct);  
    }
    return NULL;
}   

static inline MoveData randomMoveOffsetEstimation(ThreadSpecificData *thSpecific)
{
    Instance *inst = thSpecific->sol.instance;
    int n = inst->nNodes;

    #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
        float *X = thSpecific->X;
        float *Y = thSpecific->Y;
    #elif (COMPUTATION_TYPE == COMPUTE_OPTION_USE_COST_MATRIX)
        int *p = thSpecific->sol.indexPath;
    #endif

    MoveData s;

    s.index1 = genRandom(&thSpecific->rndState, 1, n); 
    s.index2 = genRandom(&thSpecific->rndState, 1, n);
    while (abs(s.index1 - s.index2) < 2)
        s.index2 = genRandom(&thSpecific->rndState, 1, n);

    if (s.index1 > s.index2)
        swapElems(s.index1, s.index2);

    #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
        s.newEdge1Cost = computeEdgeCost(X[s.index1], Y[s.index1], X[s.index2], Y[s.index2], inst);
        s.newEdge2Cost = computeEdgeCost(X[s.index1+1], Y[s.index1+1], X[s.index2+1], Y[s.index2+1], inst);
    #elif (COMPUTATION_TYPE == COMPUTE_OPTION_USE_COST_MATRIX)
        s.newEdge1Cost = inst->edgeCostMat[p[s.index1] * (size_t)n + p[s.index2]];
        s.newEdge2Cost = inst->edgeCostMat[p[s.index1+1] * (size_t)n + p[s.index2+1]];
    #endif

    s.offset = s.newEdge1Cost + s.newEdge2Cost - (thSpecific->costCache[s.index1] + thSpecific->costCache[s.index2]);
    
    return s;
}

static inline bool acceptMove(ThreadSpecificData *thSpecific, MoveData s)
{
    if (s.offset < 0)
        return true; // always accept improving moves

    double threshold;

    #ifdef USE_RATIO_ACCEPTANCE
        threshold = (s.newEdge1Cost + s.newEdge2Cost) / (thSpecific->costCache[s.index1] + thSpecific->costCache[s.index2]);
    #else
        double avgEdgeCostInSol = cvtCost2Double(thSpecific->sol.cost) / thSpecific->nNodesSqrt;
        threshold = s.offset / avgEdgeCostInSol;
    #endif

    if (threshold < thSpecific->temperature) 
        return true; 
    else
        return false; // temperature is too low for such a move
}

static inline void performMove(ThreadSpecificData *thSpecific, MoveData m)
{
    // Update cost
    thSpecific->sol.cost += cvtFloat2Cost(m.newEdge1Cost) + cvtFloat2Cost(m.newEdge2Cost) - cvtFloat2Cost(thSpecific->costCache[m.index1]) - cvtFloat2Cost(thSpecific->costCache[m.index2]);

    // Update arrays
    for (int s = m.index1+1, b = m.index2; s < b; s++, b--)
    {
        swapElems(thSpecific->sol.indexPath[s], thSpecific->sol.indexPath[b])
        #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
            swapElems(thSpecific->X[s], thSpecific->X[b])
            swapElems(thSpecific->Y[s], thSpecific->Y[b])
        #endif
    }

    // Update cost cache
    thSpecific->costCache[m.index1] = m.newEdge1Cost;
    thSpecific->costCache[m.index2] = m.newEdge2Cost;

    for (int s = m.index1+1, b = m.index2-1; s < b; s++, b--)
        swapElems(thSpecific->costCache[s], thSpecific->costCache[b])
}


static inline bool updateBestSolution(ThreadSpecificData *thSpecific)
{
    pthread_mutex_t *mutex = &thSpecific->thShared->mutex;
    Solution *bestSol = thSpecific->thShared->bestSol;
    Solution *sol = &thSpecific->sol;

    bool retVal = false;

    // checking cost twice to avoids too many mutex calls
    if (bestSol->cost > sol->cost)
    {
        pthread_mutex_lock(mutex);
        if (bestSol->cost > sol->cost)
        {
            cloneSolution(sol, bestSol);
            LOG(LOG_LVL_INFO, "Found better solution: cost = %lf", cvtCost2Double(sol->cost));
            retVal = true;
        }
        else
            thSpecific->nonImprovingIters++;
        pthread_mutex_unlock(mutex);
    }
    else
        thSpecific->nonImprovingIters++;
    
    return retVal;
}


static inline void restartOnBestSol(ThreadSpecificData *thSpecific)
{
    ThreadSharedData *thShared = thSpecific->thShared;
    Instance *inst = thSpecific->sol.instance;
    int n = inst->nNodes;

    // mutex need to be locked otherwise another thread might update bestSol while ontherone is cloninig here
    pthread_mutex_lock(&thShared->mutex);
    cloneSolution(thShared->bestSol, &thSpecific->sol);
    pthread_mutex_unlock(&thShared->mutex);

    int *solPath = thSpecific->sol.indexPath;
    solPath[n] = solPath[0];
    
    #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
        for (int i = 0; i <= n; i++)
        {
            thSpecific->X[i] = inst->X[solPath[i]];
            thSpecific->Y[i] = inst->Y[solPath[i]];
        }
    #endif

    for (int i = 0; i < n; i++)
        #if ((COMPUTATION_TYPE == COMPUTE_OPTION_AVX) || (COMPUTATION_TYPE == COMPUTE_OPTION_BASE))
            thSpecific->costCache[i] = computeEdgeCost(thSpecific->X[i], thSpecific->Y[i], thSpecific->X[i+1], thSpecific->Y[i+1], inst);
        #elif (COMPUTATION_TYPE == COMPUTE_OPTION_USE_COST_MATRIX)
            thSpecific->costCache[i] = inst->edgeCostMat[solPath[i] * (size_t)n + solPath[i+1]];
        #endif
}
